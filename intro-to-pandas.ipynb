{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e5b5ed1a-3122-44e8-bdf7-4222ec79a79c","cell_type":"markdown","source":"# Scientific Programming in Python: Tabular Data with `pandas`","metadata":{}},{"id":"2a53a1a3-fa02-47c4-9c63-4bc1c8bea468","cell_type":"markdown","source":"This tutorial focuses on introducing the libraries [`numpy`](https://numpy.org/doc/stable/) and [`pandas`](https://pandas.pydata.org/docs/). It additionally uses [`matplotlib`](https://matplotlib.org/) and [`seaborn`](https://seaborn.pydata.org/index.html) for visualization. The goal is to get the learner familiar with the basic operations of each library and their general capabilities as well as some common paradigms in how they are used.\n\nThis notebook contains the tutorial on `pandas`.","metadata":{}},{"id":"f9ab2cf4-4a10-4ab7-97fa-2fba694b33a1","cell_type":"markdown","source":"For starters, we will need to import each of these libraries. Canonically, these libraries have common import aliases.","metadata":{}},{"id":"d7df9788-a4db-486b-a47d-858298bf9a04","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"a9e8cd2b-3cc2-40fe-8fb8-5b9560b6a7ab","cell_type":"markdown","source":"## Tabular Data","metadata":{}},{"id":"80deb6fc-7568-4624-8e82-a1583f569e86","cell_type":"markdown","source":"A lot of scientific data is easily expressed, stored, and manipulated as tabular data. Tabular data is typically any data that can be represented in a spreadsheet or table. In Pandas, these tables are called dataframes. They are in many ways similar to `numpy` matrices, but they allow one to index rows and columns by names or specific numeric identifiers rather than natural numbers. Pandas also supports many utilities for combining and merging dataframes.","metadata":{}},{"id":"c7454bbe-6a8a-490b-8082-455093b4394b","cell_type":"code","source":"from cloudpathlib import S3Path, S3Client\n\nclient = S3Client(\n    no_sign_request=True,\n    local_cache_dir='/home/jovyan/cache')\nnsd_root = S3Path('s3://natural-scenes-dataset/', client=client)\n\nbehav_dirpath = nsd_root / 'nsddata' / 'ppdata' / 'subj01' / 'behav'\nwith (behav_dirpath / 'responses.tsv').open('r') as file:\n    behav_data = pd.read_csv(file, sep='\\t')\n\nbehav_data","metadata":{"scrolled":true,"trusted":false},"outputs":[],"execution_count":null},{"id":"24919247-e1a5-429e-b5d1-09efcea582b1","cell_type":"markdown","source":"## Basic Operations","metadata":{}},{"id":"22f83036-4dd4-4a72-a6ff-f5535d28afa9","cell_type":"markdown","source":"Pandas has a syntax that generally resembles that of NumPy matrices, but that enables rows and columns to have names or indices other than the natural numbers (as all arrays use). For example, a common operation on a pandas dataframe is to select the rows of the dataframe that have a particular property, such as selecting just the data from session 1 of the NSD experiments.","metadata":{}},{"id":"eec1998a-6583-4c1f-9365-1a1d964872c5","cell_type":"code","source":"ses1_data = behav_data[behav_data['SESSION'] == 1]\nses1_data","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"1ab6f467-52c9-4bb4-b693-1261e534ee09","cell_type":"markdown","source":"Similarly, we can select the rows from session 1 that are part of run 1.","metadata":{}},{"id":"a4b4ac97-97b8-41de-a059-8d9ab33010bd","cell_type":"code","source":"run1_data = ses1_data[ses1_data['RUN'] == 1]\nrun1_data","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"4bbcdc13-7f74-44a5-9ead-fce60d41d97f","cell_type":"markdown","source":"Alternatively, we could have selected all of the session 1 run 1 rows in one go if we combine the conditions using a logical intersection `&` operator:","metadata":{}},{"id":"e6bd1dd9-642c-4b0d-a064-ac1e0ed1ed7c","cell_type":"code","source":"behav_data[(behav_data['SESSION'] == 1) & (behav_data['RUN'] == 1)]","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"ce3daf65-9556-45f7-9f8f-7a57267f3026","cell_type":"markdown","source":"Now that we have selected a single subject, session, and run, we might want to look at the distribution of reaction times (the `'RT'` column) that the subject had when doing the task. We can access columns of a datafram as if the dataframe were a dictionary of columns.","metadata":{}},{"id":"8489ade2-3d34-4c0e-ab01-d2a244951682","cell_type":"code","source":"plt.hist(run1_data['RT'])","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"eea8af2a-1a7e-4fc9-98a6-68810a200beb","cell_type":"markdown","source":"Notice that there are multiple meanings to the syntax `dataframe[arg]` depending on the `arg`. If `arg` is a column name (string) or a list of column names, then those columns are selected and dataframe representing only the listed column(s) is returned. If `arg` is a boolean mask, then it is applied to the rows.\n\nTo access sub-elements or sub-dataframes of a dataframe according to its axes (which are the same as in a NumPy array: axis 0 is the rows and axis 1 is the columns), one can use either the `dataframe.loc` or `dataframe.iloc` interfaces.\n\nThe `dataframe.iloc[rows, cols]` interface is basically equivalent to indexing into a numpy matrix; row `0` will be the first row in the dataframe and column `0` will be the first column.\n\nThe `dataframe.loc[rows, cols]`, on the other hand, expects the `rows` and `cols` to be index values in the dataframe. The dataframes we've loaded and made so far have been automatically given row indices by Pandas that are equivalent to the NumPy array indices (i.e., the first row has index 0, the next has index 1, etc.). The columns are indexed according to the column names, however.","metadata":{}},{"id":"e29b5ba6-17b3-4d03-8570-d7677aa79b1f","cell_type":"code","source":"# Extract the first 10 rows of the RT column using iloc; the column index for\n# 'RT' is 9:\nrun1_data.iloc[:10, 9]","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"a5507ba2-4acf-46dd-94d4-ab590d54b931","cell_type":"code","source":"# Extract the first 10 rows of the RT column using loc:\nrun1_data.loc[:10, 'RT']","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"cd310769-b5db-4d9e-bca8-5e78abed8612","cell_type":"markdown","source":"Since the rows of run1_data are naturally indexed by the trial number, we might want to give this dataframe its own index. In this case, it would mean that `run1_data.loc[1]` returned the row for trial 1; currently `run1_data.loc[0]` is required to extract trial 1.\n\nBecause Python uses zero-based indexing, one may or may not prefer to make this indexing change, but in many cases, for example in projects like the Human Connectome Project where subjects have random IDs like `111312`, it can be useful to request `dataframe.loc[111312]` instead of figuring out which row contains that particular subject.","metadata":{}},{"id":"b127820f-de0b-42cf-85da-1c039a8ce3c0","cell_type":"code","source":"run1_data_indexed = run1_data.set_index('TRIAL')\nrun1_data_indexed.loc[[1,2,3]]","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"bd70aa63-c2d0-4ada-8481-076128cb1272","cell_type":"code","source":"run1_data_indexed.iloc[[1,2,3]]","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"b1d5c55f-cb38-428a-b7e9-691e3987751a","cell_type":"markdown","source":"Certain pandas operations return dataframes whose rows *and* columns are labeled by strings instead of numbers. Rows can have many kinds of indices, and it's possible to make dataframes with various kinds of row indices including multi-indices (see the [pandas guide to indexing and selecting data](https://pandas.pydata.org/docs/user_guide/indexing.html) for more information).\n\nThe `corr` method is an example of a method that produces a dataframe whose rows and columns are labeled by strings.","metadata":{}},{"id":"275fd455-fba3-4523-b0f6-7f459f8d3485","cell_type":"code","source":"# Select a subset of the columns that we care about.\ndata = behav_data[['SUBJECT', 'SESSION', 'RUN', 'RT', 'ISCORRECT']]\n\n# Calculate the correlation of all columns to all others; use the\n# Spearman (rank) correlation.\ncorr = data.corr(method='spearman')\n\n# Show the resulting dataframe:\ncorr","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"98889d07-b81e-4db4-b455-8f6f22b676e7","cell_type":"markdown","source":"To select rows and columns, we can use `loc` and `iloc` just as before, but when using `loc`, the row values are strings now.","metadata":{}},{"id":"bcf8b78b-42a5-4707-b735-3248d6b433a9","cell_type":"code","source":"corr.loc[['SESSION', 'RUN'], 'RT']","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"fb3969fb-e742-4d68-a2a2-2f92214ffbdc","cell_type":"markdown","source":"## Grouping DataFrames","metadata":{}},{"id":"6543b0c4-86e9-4783-9420-36b0edaea0e0","cell_type":"markdown","source":"One of the most common operations one needs to run on a dataframe is to subdivide it into smaller dataframes then to perform operations over those subsets of the dataframe, for example to run an analysis over each individual session in our subject's behavioral dataframe.\n\nThis can be done by looping over a dataframe and making the clusters manually, but there are builtin methods that can make this a lot easier. Let's look at how we would divide the session 1 data from our subject up into runs then calculate some basic statistics on each run.","metadata":{}},{"id":"94992d99-6839-421f-956c-e937806933db","cell_type":"code","source":"# We use the groupby method; here we provide just one column name, but a list\n# of columns can also be given.\nses1_groups = ses1_data.groupby('RUN')\n\n# The groupby method returns a special kind of group-by object:\nses1_groups","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"17b419e7-a952-4b4c-ab9b-150550ad53d5","cell_type":"code","source":"# If we want to calculate the mean of the columns in each group, there's a\n# builtin method for that! It even returns a dataframe indexed by the column\n# (or columns) that we grouped by:\nmeans = ses1_groups.mean()\n\n# Notice that the index of the returned dataframe is the RUN column:\nmeans","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"f81fad16-4e35-487a-9a46-896c51b9eff6","cell_type":"code","source":"# Similarly we can calculate other statistics like the standard deviation:\nstds = ses1_groups.std()","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"75644cbf-f600-4689-881f-1b3b83856d82","cell_type":"code","source":"# One can also loop over a group:\nfor (run_id, group) in ses1_groups:\n    print(f'Run {run_id:2d}: mean RT = {np.mean(group[\"RT\"]):7.2f}')","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"c2b110c4-3345-433a-b67e-697511f46cf2","cell_type":"markdown","source":"## Combining DataFrames","metadata":{}},{"id":"57ce039c-41de-4ef9-bdd1-fac382caef3d","cell_type":"markdown","source":"Now that we've created a dataframe of the means of the columns for each run and the standard deviations of the columns for those runs in the section above (`means` and `stds`), we might want to examing how the reaction time changes from one run to the next. We might even hypothesize that as the subject practices the task, they will get faster.\n\nTo do this analysis, we might want to start by reducing the dataframes down to just the parts we care about (e.g., the reaction times `'RT'` and whether the got the trial correct `'ISCORRECT'`).","metadata":{}},{"id":"dbfd3467-8f3f-4a06-9e60-6397d700a135","cell_type":"code","source":"means = means[['ISCORRECT', 'RT']]\nstds = stds[['ISCORRECT', 'RT']]\n\n# Look at the means:\nmeans","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"5d0e2c49-0bdc-4af2-bebe-3687647b6513","cell_type":"markdown","source":"### Merging DataFrames","metadata":{}},{"id":"4ac89fac-e000-4df4-a579-0b274a9b092b","cell_type":"markdown","source":"It would be nice for the sake of other operations we might want to do, like iterating through the data or plotting, if we had the columns of the `means` dataframe and the columns of the `stds` dataframe together in a single dataframe, for example with the columns `ISCORRECT_mean`, `ISCORRECT_std`, `RT_mean`, and `RT_std`.\n\nTo combine dataframes like this, we use the `pandas.merge` function.","metadata":{}},{"id":"ced7b0f8-177f-45fe-8572-9b07c181a209","cell_type":"code","source":"# Merge the means and stds together using the column RUN to decide whether two\n# rows of the dataframe should be merged.\nrt_stats = pd.merge(means, stds, on='RUN')\nrt_stats","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"07dcd311-f981-4499-8c3c-1c5613a5f0e4","cell_type":"markdown","source":"The above cell worked fine for combining the columns, but we'd like the columns to have specific names that are meaningful to us:","metadata":{}},{"id":"325b056f-a498-42ca-8b07-99b5d16432c0","cell_type":"code","source":"rt_stats = pd.merge(means, stds, on='RUN', suffixes=('_mean', '_std'))\nrt_stats","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"66bef06d-dd26-43f4-84f3-f846644bffc9","cell_type":"code","source":"# Notice that the RUN number in these dataframes is now part of the index, and\n# so we access it using .index instead of ['RUN']:\nrt_stats.index","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"a00a0b99-e172-465f-b931-c190ff937226","cell_type":"markdown","source":"To test our theory about reaction times, we can extract data by column to make a quick matplotlib plot of the average reaction time across trials, ± the standard deviation.","metadata":{}},{"id":"f31ef91e-19e5-4135-a7f5-d3fb0334f452","cell_type":"code","source":"plt.errorbar(\n    rt_stats.index, rt_stats['RT_mean'], rt_stats['RT_std'],\n    fmt='o:')","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"9721a579-c4ae-4ba7-8f0e-b364ff6afad2","cell_type":"markdown","source":"This plot doesn't really support our hypothesis that the reaction times would decrease across runs as the subject gained experience.\n\nA better plot would use the standard error instead of the standard deviation. To obtain this, we would need to get the count of trials in each of our groups. This can be accomplished with the `count` method.","metadata":{}},{"id":"0db46853-13c5-466b-a482-0dc9dcc35325","cell_type":"code","source":"# Produce a dataframe similar to means and stds but containing counts of the\n# number of trials in each run.\ncounts = ses1_groups.count()[['ISCORRECT', 'RT']]\n\n# Let's try merging without suffixes...\npd.merge(rt_stats, counts, on='RUN')","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"3f186f07-b2f6-4844-8602-0c82b65d3437","cell_type":"code","source":"# To get nice columns like RT_count into our dataframe, we can rename the\n# columns of counts to RT_count and ISCORRECT_count then merge on RUN:\nrename_cols = {'ISCORRECT': 'ISCORRECT_count', 'RT': 'RT_count'}\nrt_stats = pd.merge(\n    rt_stats,\n    counts.rename(columns=rename_cols),\n    on='RUN')\n\nrt_stats","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"ddf1fac7-2d96-45f8-a1d3-4cea6815dab3","cell_type":"code","source":"# Now we can remake our error plot using standard error.\nplt.errorbar(\n    rt_stats.index, rt_stats['RT_mean'],\n    rt_stats['RT_std'] / np.sqrt(rt_stats['RT_count']),\n    fmt='o:')\nplt.xlabel('Run Number')\nplt.ylabel('Reaction Time [ms]')","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"6d4725ac-9488-4bfe-b337-03ca74214e18","cell_type":"markdown","source":"### Concatenating DataFrames","metadata":{}},{"id":"a28b2300-8ad2-4cac-9727-db24eb547a26","cell_type":"markdown","source":"Another common way that we need to combine dataframes is when we have several dataframes with the same columns that need to be appended together. For this we can use the `pandas.concat` function. This function requires a list of dataframes which are concatenated vertically in order.\n\nFor example, let's load in the NSD behavioral data for all of the subjects and concatenate them into one large dataframe that contains all subjects, sessions, runs, and trials!","metadata":{}},{"id":"6db24bb8-5878-4cf9-80c2-d37948e521ea","cell_type":"code","source":"# This is the data that contains preprocessed subject data; each subejct has a\n# sub-directory in this directory.\nppdata_dirpath = nsd_root / 'nsddata' / 'ppdata'\n\n# We'll iterate through each subdirectory (one per subject), load in their\n# dataframe, and append it to the all_data list (which we will pass into\n# pd.concat at the end of the loop.\nall_data = []\nfor subj_dirpath in ppdata_dirpath.iterdir():\n    with (subj_dirpath / 'behav' / 'responses.tsv').open('r') as file:\n        subj_behav_data = pd.read_csv(file, sep='\\t')\n    all_data.append(subj_behav_data)\n\n# Concatenate all the individual dataframes into one giant one:\nall_data = pd.concat(all_data, ignore_index=True)","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"08ab8357-e6c5-4b06-8e9d-283afebcc556","cell_type":"code","source":"all_data","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"9e6bccc2-4f07-4f1e-8ba2-0bd36a3488c6","cell_type":"markdown","source":"## Seaborn For Visualizing DataFrames","metadata":{}},{"id":"4017545c-8da4-4829-a35a-9f4f2fa63b4f","cell_type":"markdown","source":"A very useful library for quickly looking at variation in a dataset that is stored in a pandas dataframe is a library called [Seaborn](https://seaborn.pydata.org/). Seaborn offers a fairly intuitive interface to many useful scientific plots, and learning its interface is often best done through examples: see in particular the [Seaborn example gallery](https://seaborn.pydata.org/examples/index.html).\n\nFor example, if we wanted to look at how the reaction times of subjects varied across runs in their first session, we could select the subdataframe for the first session then instruct Seaborn to organize a set of violin-plots of the reaction time by subject and run.","metadata":{}},{"id":"906aa9b0-1e66-4453-877c-894ceb852b70","cell_type":"code","source":"# Seaborn is typically imported as sns.\nimport seaborn as sns\n\n# Make a matplotlib figure and one set of axes on which to draw.\n(fig,ax) = plt.subplots(1,1, figsize=(7,5), dpi=288)\n\n# We use seaborn's violinplot function:\nsns.violinplot(\n    # The data we want seaborn to plot:\n    data=all_data[all_data['SESSION'] == 1],\n    # Along the x-axis we want histograms grouped by subject.\n    x='SUBJECT',\n    # We want the histograms to be the reaction time, along the y-axis.\n    y='RT',\n    # We want to additionally color the different histograms by the run.\n    hue='RUN',\n    # We don't want to draw boundary lines on the histograms.\n    linewidth=0,\n    # Plot on this set of axes:\n    ax=ax)\n\nplt.show()","metadata":{"trusted":false},"outputs":[],"execution_count":null}]}